{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd08b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0703fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('tokenization_dataset (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e05520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NLP is amazing</td>\n",
       "      <td>['NLP','is','amazing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I love machine learning</td>\n",
       "      <td>['I','love','machine','learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tokenization breaks text into words</td>\n",
       "      <td>['Tokenization','breaks','text','into','words']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Python is used in NLP</td>\n",
       "      <td>['Python','is','used','in','NLP']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deep learning uses neural networks</td>\n",
       "      <td>['Deep','learning','uses','neural','networks']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                           input_text  \\\n",
       "0   1                       NLP is amazing   \n",
       "1   2              I love machine learning   \n",
       "2   3  Tokenization breaks text into words   \n",
       "3   4                Python is used in NLP   \n",
       "4   5   Deep learning uses neural networks   \n",
       "\n",
       "                                            tokens  \n",
       "0                           ['NLP','is','amazing']  \n",
       "1                ['I','love','machine','learning']  \n",
       "2  ['Tokenization','breaks','text','into','words']  \n",
       "3                ['Python','is','used','in','NLP']  \n",
       "4   ['Deep','learning','uses','neural','networks']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140de59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13013fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'delhi',\n",
       " 'I',\n",
       " 'will',\n",
       " 'stay',\n",
       " 'there',\n",
       " 'for',\n",
       " '3',\n",
       " 'days']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using split function\n",
    "sen1='I am going to delhi I will stay there for 3 days'\n",
    "sen1.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ef4bc",
   "metadata": {},
   "source": [
    "using split function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a1fbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'going', 'to', 'delhi?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen2='i am going to delhi?'\n",
    "sen2.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01e876",
   "metadata": {},
   "source": [
    "#Using NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce52ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983abc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize ,sent_tokenize\n",
    "sen1='I am going to delhi I will stay there for 3 days'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1db52",
   "metadata": {},
   "source": [
    "#word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8e81a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'delhi',\n",
       " 'I',\n",
       " 'will',\n",
       " 'stay',\n",
       " 'there',\n",
       " 'for',\n",
       " '3',\n",
       " 'days']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a04e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3='NLP is amazing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1dd6856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'amazing']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8022dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4='Natural Language Processing is an important field of artificial intelligence. It helps machines understand human language. Sentence tokenization is one of the first steps in NLP. In this step, a paragraph is broken into individual sentences. This makes further processing easier. Many NLP tasks like sentiment analysis and text summarization depend on accurate sentence tokenization. Therefore, understanding sentence tokenization is essential for building real-world NLP applications.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805c82b",
   "metadata": {},
   "source": [
    "#sentences tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20e43243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Processing is an important field of artificial intelligence.',\n",
       " 'It helps machines understand human language.',\n",
       " 'Sentence tokenization is one of the first steps in NLP.',\n",
       " 'In this step, a paragraph is broken into individual sentences.',\n",
       " 'This makes further processing easier.',\n",
       " 'Many NLP tasks like sentiment analysis and text summarization depend on accurate sentence tokenization.',\n",
       " 'Therefore, understanding sentence tokenization is essential for building real-world NLP applications.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6331960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6='नैसर्गिक भाषा प्रक्रिया हे कृत्रिम बुद्धिमत्तेचे एक महत्त्वाचे क्षेत्र आहे. यामुळे संगणकाला मानवी भाषा समजण्यास मदत होते. या प्रक्रियेत टोकनायझेशन ही पहिली पायरी असते. टोकनायझेशनमध्ये मजकूर लहान शब्दांमध्ये किंवा वाक्यांमध्ये विभागला जातो. यामुळे पुढील प्रक्रिया सोपी होते. अनेक NLP अनुप्रयोग जसे की भावना विश्लेषण आणि मजकूर संक्षेप यासाठी योग्य टोकनायझेशन आवश्यक असते.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b7346b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['नैसर्गिक',\n",
       " 'भाषा',\n",
       " 'प्रक्रिया',\n",
       " 'हे',\n",
       " 'कृत्रिम',\n",
       " 'बुद्धिमत्तेचे',\n",
       " 'एक',\n",
       " 'महत्त्वाचे',\n",
       " 'क्षेत्र',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'यामुळे',\n",
       " 'संगणकाला',\n",
       " 'मानवी',\n",
       " 'भाषा',\n",
       " 'समजण्यास',\n",
       " 'मदत',\n",
       " 'होते',\n",
       " '.',\n",
       " 'या',\n",
       " 'प्रक्रियेत',\n",
       " 'टोकनायझेशन',\n",
       " 'ही',\n",
       " 'पहिली',\n",
       " 'पायरी',\n",
       " 'असते',\n",
       " '.',\n",
       " 'टोकनायझेशनमध्ये',\n",
       " 'मजकूर',\n",
       " 'लहान',\n",
       " 'शब्दांमध्ये',\n",
       " 'किंवा',\n",
       " 'वाक्यांमध्ये',\n",
       " 'विभागला',\n",
       " 'जातो',\n",
       " '.',\n",
       " 'यामुळे',\n",
       " 'पुढील',\n",
       " 'प्रक्रिया',\n",
       " 'सोपी',\n",
       " 'होते',\n",
       " '.',\n",
       " 'अनेक',\n",
       " 'NLP',\n",
       " 'अनुप्रयोग',\n",
       " 'जसे',\n",
       " 'की',\n",
       " 'भावना',\n",
       " 'विश्लेषण',\n",
       " 'आणि',\n",
       " 'मजकूर',\n",
       " 'संक्षेप',\n",
       " 'यासाठी',\n",
       " 'योग्य',\n",
       " 'टोकनायझेशन',\n",
       " 'आवश्यक',\n",
       " 'असते',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent_tokenize(text6)\n",
    "word_tokenize(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cfa9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b8369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
